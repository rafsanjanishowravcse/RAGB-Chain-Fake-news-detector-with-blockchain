{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a94f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\rahul\\OneDrive\\7_Learning\\IISC\\Courses\\3.1_Deep_Learning\\Course Material\\Project\\wip\n",
      "SARVAM API KEY FOUND\n",
      "GROK API KEY FOUND\n",
      "SERP DEV API KEY FOUND\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "load_dotenv()\n",
    "\n",
    "sarvam_api_key = os.getenv(\"SARVAM_API_KEY\")\n",
    "if sarvam_api_key:\n",
    "    print('SARVAM API KEY FOUND')\n",
    "else:\n",
    "    print(\"No SARVAM API key found\")\n",
    "\n",
    "grok_api_key = os.getenv(\"GROK_API_KEY\")\n",
    "if grok_api_key:\n",
    "    print('GROK API KEY FOUND')\n",
    "else:\n",
    "    print(\"No GROK API key found\")\n",
    "\n",
    "serp_dev_api_key = os.getenv(\"SERP_DEV_API_KEY\")\n",
    "if serp_dev_api_key:\n",
    "    print('SERP DEV API KEY FOUND')\n",
    "else:\n",
    "    print(\"No SERP API key found\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "model_multi_query = os.getenv('model_multi_query')\n",
    "model_summarizer = os.getenv('model_summarizer')\n",
    "model_judge = os.getenv('model_judge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d2bd1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import mimetypes\n",
    "import os\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "from sarvamai import SarvamAI\n",
    "import re\n",
    "\n",
    "grok_api_key = os.getenv('GROK_API_KEY')\n",
    "serp_dev_api_key = os.getenv('SERP_DEV_API_KEY')\n",
    "sarvam_api_key = os.getenv('SARVAM_API_KEY')\n",
    "\n",
    "empty_search = None\n",
    "\n",
    "class SerperRetrieverWrapper:\n",
    "    #Class to use Serper as retriver agent for the RAG framework\n",
    "    def __init__(self, api_key: str, num_results: int = 15):\n",
    "        self.api_key = api_key\n",
    "        self.num_results = num_results\n",
    "    \n",
    "    def get_relevant_documents(self, query: str):\n",
    "        \"\"\"\n",
    "        Query Serper.dev and return up to `num_results` organic search hits.\n",
    "        Each hit is a dict: { \"title\": str, \"link\": str, \"snippet\": str }.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            _SERPER_SEARCH_URL = \"https://google.serper.dev/news\"\n",
    "            q1 = '(site:news18.com OR site:ptinews.com OR site:politifact.com) ' + query\n",
    "            #print('Serper query: ', q1)\n",
    "    \n",
    "            headers = {\n",
    "                \"X-API-KEY\": self.api_key,\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "            payload = {\n",
    "                \"q\": q1,\n",
    "                \"num\": self.num_results,\n",
    "            }\n",
    "            \n",
    "            resp = requests.post(_SERPER_SEARCH_URL, headers=headers, json=payload)\n",
    "            #print('Serper response: ', resp)\n",
    "            #print('Serper response code: ', resp.json())\n",
    "            \n",
    "            if resp.status_code != 200:\n",
    "                raise Exception(f\"Serper API Error: {resp.text}\")\n",
    "            results = resp.json()\n",
    "            #print('Serper results: ', results.type)\n",
    "\n",
    "            #return results\n",
    "            \n",
    "            documents = []\n",
    "            for i, item in enumerate(results.get(\"news\", []), 1):\n",
    "                title = item.get('title')\n",
    "                link = item.get('link')\n",
    "                snippet = item.get('snippet')\n",
    "                documents.append(Document(\n",
    "                    page_content=f\"{title}\\n{snippet}\",\n",
    "                    metadata={\"source\": link}\n",
    "                ))\n",
    "            \n",
    "            #if not documents:\n",
    "            #    empty_search = Exception(\"No result found\")\n",
    "            #    raise empty_search\n",
    "            \n",
    "            #print(f\"Retrieved {len(documents)} documents from Serper.\")\n",
    "            return documents\n",
    "        except Exception as e:\n",
    "            if e is empty_search:\n",
    "                print('serper main exception1')\n",
    "                raise empty_search\n",
    "            else:\n",
    "                print('serper main exception2')\n",
    "                raise e\n",
    "        \n",
    "def verify_news(user_claim, input_lang = 'auto'):\n",
    "    \"\"\"\n",
    "       Description: This function is used to verify the claim provided by the user and output as REAL or FAKE or UNSURE based on the context with a short explanation\n",
    "       INPUT: user_claim --> The news user wish to verify\n",
    "       OUTPUT: FAKE/REAL/UNSURE with explanation\n",
    "    \"\"\"\n",
    "    try:\n",
    "       print('Starting verification process for claim')             \n",
    "\n",
    "       #print('here1: ', user_claim)\n",
    "       claim1 = user_claim.replace(\"'\",\"\").replace(\"\\n\",\" \")\n",
    "        \n",
    "       serper_retriever = SerperRetrieverWrapper(api_key=serp_dev_api_key)\n",
    "       context_retriever = RunnableLambda(serper_retriever.get_relevant_documents)\n",
    "       \n",
    "       \"\"\"\n",
    "       Implemeting RAG framework with Multi Query Translation\n",
    "       Step 1 -- Take input from user for the news to verify\n",
    "       Step 2 -- Generate 3 variants of the news for better seach results\n",
    "       Step 3 -- Summarise the results from all the previous steps to be passed to main prompt\n",
    "       Step 4 -- Deliver the final verdict with a short explanation\n",
    "       \"\"\"\n",
    "       \n",
    "       #Multi Query Generation\n",
    "       \n",
    "       multi_query_template = \"\"\"\n",
    "            You are an AI language assistant.\n",
    "\n",
    "             Your task is to generate three alternative phrasings of the given user question to help retrieve relevant documents from a vector database. These alternatives should reflect different ways the original question might be asked, using varied vocabulary or structure, while preserving the original intent.             \n",
    "             This helps improve the chances of matching relevant content in a distance-based similarity search.\n",
    "             \n",
    "             Original question: {question}\n",
    "             \n",
    "             Output:\n",
    "             Provide exactly three reworded versions of the question, each on a new line.\n",
    "       \"\"\"\n",
    "       perspectives_prompt = ChatPromptTemplate.from_template(multi_query_template)\n",
    "       \n",
    "       llm_multi_query = ChatGroq(api_key = grok_api_key, model_name = model_multi_query)\n",
    "       \n",
    "       generate_queries = (\n",
    "           perspectives_prompt \n",
    "           | llm_multi_query\n",
    "           | StrOutputParser() \n",
    "           | (lambda x: x.split(\"\\n\"))\n",
    "       )\n",
    "       \n",
    "       #Summarization using multi query\n",
    "       \n",
    "       summarizer_template = '''\n",
    "          You are an assistant summarizing factual evidence from multiple documents.\n",
    "       \n",
    "          Based on the following documents, extract the key facts relevant to the claim.\n",
    "          \n",
    "          Claim: {question}\n",
    "          \n",
    "          Documents:\n",
    "          {context}\n",
    "          \n",
    "          Return a short neutral summary of the key facts only.\n",
    "       '''\n",
    "       summarizer_prompt = PromptTemplate.from_template(summarizer_template)\n",
    "       \n",
    "       llm_summarizer = ChatGroq(api_key = grok_api_key, model_name = model_summarizer)\n",
    "       summarizer_chain = (\n",
    "           {\n",
    "               \"context\": context_retriever,\n",
    "               \"question\": generate_queries\n",
    "           }\n",
    "           | summarizer_prompt\n",
    "           | llm_summarizer\n",
    "           | StrOutputParser()\n",
    "       )\n",
    "       \n",
    "       #Final Judgement \n",
    "       \n",
    "       fact_checker_template = '''\n",
    "          You are a fact-checking assistant. Give a direct answer without showing your thinking process.\n",
    "          \n",
    "          Claim: {question}\n",
    "          \n",
    "          Evidence:\n",
    "          {evidence}\n",
    "          \n",
    "          Instructions:\n",
    "          \n",
    "          If evidence is provided, use only that evidence to determine whether the claim is REAL, FAKE, or UNSURE.          \n",
    "          If no evidence is provided, conduct a brief web search to gather supporting or contradicting information. Prioritize information from reliable, reputable sources such as news websites, fact-checking organizations, or official statements.\n",
    "          \n",
    "          If no sufficient or conclusive evidence is found from these sources, respond with UNSURE.          \n",
    "          Do not speculate or rely on untrusted sources.\n",
    "\n",
    "          Respond in this format:\n",
    "          \n",
    "          Classification: REAL / FAKE / UNSURE  \n",
    "          Explanation: <Your reasoning, clearly supported by the evidence or source content> \n",
    "       '''\n",
    "       \n",
    "       fact_checker_prompt = PromptTemplate.from_template(fact_checker_template)\n",
    "       \n",
    "       llm_fact_checker = ChatGroq(api_key = grok_api_key, model_name = model_judge)\n",
    "       fact_checker_chain = (\n",
    "           {\n",
    "               \"question\": RunnablePassthrough(),\n",
    "               \"evidence\": summarizer_chain \n",
    "           }\n",
    "           | fact_checker_prompt\n",
    "           | llm_fact_checker\n",
    "           | StrOutputParser()\n",
    "       )\n",
    "   \n",
    "       claim = claim1\n",
    "       \n",
    "       #Calling SARVAM API to translate Indic languages to English\n",
    "       client = SarvamAI(api_subscription_key = sarvam_api_key)\n",
    "       \n",
    "       try:\n",
    "           translation = client.text.translate(\n",
    "           input=claim,\n",
    "           source_language_code=\"auto\",\n",
    "           target_language_code=\"en-IN\"\n",
    "           )\n",
    "       except Exception as e:\n",
    "           print(f\"Error during translation: {e}\")\n",
    "           error_msg = 'It appears you have provided input in an alien language. Please try again with some other language'\n",
    "           return error_msg,error_msg,error_msg\n",
    "       \n",
    "       claim_final = translation.translated_text if translation else claim\n",
    "       claim_orig_lang = translation.source_language_code\n",
    "       #print(f\"Translated claim: {claim_final}\")\n",
    "       \n",
    "       verdict_orig = fact_checker_chain.invoke(claim_final)\n",
    "       verdict_class = verdict_orig.split('\\n')[0]\n",
    "       verdict_explan = verdict_orig.split('\\n')[-1]\n",
    "\n",
    "       # Strip out any <think> or <tool> or similar tags\n",
    "       cleaned_output = re.sub(r\"<[^>]+>\", \"\", verdict_orig).strip()\n",
    "       \n",
    "       verdict_class = re.search(r'Classification:\\s*(REAL|FAKE|UNSURE)', cleaned_output)\n",
    "       verdict_explan = re.search(r'Explanation:\\s*(.*)', cleaned_output, re.DOTALL)\n",
    "       \n",
    "       verdict_class = verdict_class.group(1) if verdict_class else \"UNSURE\"\n",
    "       verdict_explan = verdict_explan.group(1).strip() if verdict_explan else \"No clear explanation found.\"\n",
    "\n",
    "       #print('here1: ',verdict_class)\n",
    "       #print('here2: ',verdict_explan)\n",
    "       \n",
    "       if input_lang == 'auto':\n",
    "           trans_lang = claim_orig_lang\n",
    "       else:\n",
    "           trans_lang = input_lang\n",
    "   \n",
    "       if claim_orig_lang != 'en-IN':\n",
    "           try:\n",
    "               translation_class = client.text.translate(\n",
    "               input=verdict_class,\n",
    "               source_language_code='en-IN',\n",
    "               target_language_code=claim_orig_lang\n",
    "               )\n",
    "           except Exception as e:\n",
    "               print(f\"Error during verdict translation: {e}\")  \n",
    "               error_msg = 'Something went wrong while translating the verdict. Please try again'\n",
    "               return error_msg,error_msg,error_msg\n",
    "               \n",
    "           try:\n",
    "               translation_explan = client.text.translate(\n",
    "               input=verdict_explan,\n",
    "               source_language_code='en-IN',\n",
    "               target_language_code=claim_orig_lang\n",
    "               )\n",
    "           except Exception as e:\n",
    "               print(f\"Error during verdict translation: {e}\")  \n",
    "               error_msg = 'Something went wrong while translating the verdict. Please try again'\n",
    "               return error_msg,error_msg,error_msg\n",
    "           \n",
    "           verdict_trans_class = translation_class.translated_text\n",
    "           verdict_trans_explan = translation_explan.translated_text\n",
    "           verdict_trans = verdict_trans_class + '\\n\\n' + verdict_trans_explan\n",
    "           \n",
    "           verdict_orig = verdict_class + '\\n\\n' + verdict_explan\n",
    "       else:\n",
    "           verdict_orig = verdict_class + '\\n\\n' + verdict_explan\n",
    "           verdict_trans_class = verdict_class\n",
    "           verdict_trans_explan = verdict_explan\n",
    "           verdict_trans = verdict_trans_class + '\\n\\n' + verdict_trans_explan\n",
    "           #print('verdict_orig: ', verdict_orig) \n",
    "           \n",
    "           try:\n",
    "               match = re.search(r':(.*)', verdict_class)\n",
    "               if match:\n",
    "                    verdict1 = match.group(1).strip()\n",
    "                    #print(verdict1)\n",
    "           except Exception as e:\n",
    "               print('here3')\n",
    "               verdict1 = verdict_class\n",
    "       \n",
    "       #return(claim_final, verdict_orig, verdict_trans)\n",
    "       return(claim_final, verdict_class, verdict_orig)\n",
    "    except Exception as e:\n",
    "        if str(e) == 'No result found':\n",
    "            print('Error in main proc1. Error is ', e)\n",
    "            error_msg = 'The search for this claim came back empty. Please rephrase the claim or try with a new one'\n",
    "            return('UNSURE' ,error_msg,error_msg)\n",
    "        else:\n",
    "            print('Error in main proc2. Error is ', e)\n",
    "            error_msg = 'Something went wrong. Please try after some time'\n",
    "            return(error_msg,error_msg,error_msg)\n",
    "    \n",
    "def transcribe_audio(audio):\n",
    "    \"\"\"\n",
    "       Description: This function trascibes audio using SarvamAI STT model \n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = SarvamAI(api_subscription_key = sarvam_api_key)\n",
    "        mime_type, _ = mimetypes.guess_type(audio)\n",
    "        \n",
    "        with open(audio, \"rb\") as f:\n",
    "            response = client.speech_to_text.transcribe(\n",
    "                file=(\"audio.mp3\", f, mime_type or \"audio/mpeg\"),\n",
    "                model=\"saarika:v2.5\",\n",
    "                language_code=\"unknown\"\n",
    "            )\n",
    "        ret_var = response.transcript\n",
    "        ret_lang = response.language_code\n",
    "    except Exception as e:\n",
    "        print(f\"Error during translation: {e}\")\n",
    "        ret_var = ''\n",
    "\n",
    "    return ret_var, ret_lang\n",
    "    \n",
    "def verify_news_audio(audio):\n",
    "    \"\"\"\n",
    "       Description: This function verifies the news where input method is Audio\n",
    "    \"\"\"\n",
    "    \n",
    "    claim, orig_lang = transcribe_audio(audio)\n",
    "    if claim == '':\n",
    "        error_msg = 'I could not understand your message. Please try recording again'\n",
    "        return(error_msg,error_msg,error_msg)\n",
    "    \n",
    "    final_claim, verdict, verdict_trans = verify_news(claim, orig_lang)\n",
    "    return final_claim, verdict, verdict_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f460b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting verification process for claim\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('The Earth is flat.',\n",
       " 'FAKE',\n",
       " 'FAKE\\n\\nThe evidence includes fact-checking organizations like Politifact refuting flat Earth claims by citing satellite imagery, high-altitude footage demonstrating Earth\\'s curvature, and corrected misinterpretations (e.g., Hillary Clinton\\'s \"glass ceiling\" quote). A former flat Earth advocate (Jeran Campanella) recanted his belief after visiting Antarctica, and the development of a two-sided spherical map underscores Earth\\'s true shape. These sources consistently contradict the \"flat Earth\" claim.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim = \"The Earth is flat.\"\n",
    "verify_news(claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "383e8df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = 'C:\\\\Users\\\\rahul\\\\OneDrive\\\\7_Learning\\\\IISC\\\\Courses\\\\3.1_Deep_Learning\\\\Course Material\\\\Project\\\\wip\\\\Recording.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9fe9a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting verification process for claim\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('India sent its first specs on Jupiter.',\n",
       " 'FAKE',\n",
       " 'FAKE\\n\\nThe provided evidence exclusively references TVS Jupiter as a scooter model produced by TVS Motor Company in India. There is no mention of any space-related mission, planetary exploration, or transmission of specifications related to the planet Jupiter. The term \"Jupiter\" in the documents refers to consumer vehicles, making the claim about India sending \"specs on Jupiter\" unrelated to the evidence provided.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_news_audio(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5856ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df342235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a77318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc27cd09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea5aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d93e283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05759305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0190df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
