{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "385f0947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\rahul\\OneDrive\\7_Learning\\IISC\\Courses\\3.1_Deep_Learning\\Course Material\\Project\\wip\n",
      "SARVAM API KEY FOUND\n",
      "GROK API KEY FOUND\n",
      "SERP DEV API KEY FOUND\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "load_dotenv()\n",
    "\n",
    "sarvam_api_key = os.getenv(\"SARVAM_API_KEY\")\n",
    "if sarvam_api_key:\n",
    "    print('SARVAM API KEY FOUND')\n",
    "else:\n",
    "    print(\"No SARVAM API key found\")\n",
    "\n",
    "grok_api_key = os.getenv(\"GROK_API_KEY\")\n",
    "if grok_api_key:\n",
    "    print('GROK API KEY FOUND')\n",
    "else:\n",
    "    print(\"No GROK API key found\")\n",
    "\n",
    "serp_dev_api_key = os.getenv(\"SERP_DEV_API_KEY\")\n",
    "if serp_dev_api_key:\n",
    "    print('SERP DEV API KEY FOUND')\n",
    "else:\n",
    "    print(\"No SERP API key found\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "#model_multi_query = 'llama3-8b-8192'\n",
    "#model_summarizer = 'llama3-8b-8192'\n",
    "#model_judge = 'llama3-8b-8192'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee2febff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(train_file_name='fake_news_claims_factchecked.csv'):\n",
    "    \"\"\"\n",
    "       Description: This function evaluates the model performance and returns the dataframe\n",
    "    \"\"\"\n",
    "    models = ['llama3-8b-8192','qwen/qwen3-32b','mistral-saba-24b','deepseek-r1-distill-llama-70b',\n",
    "              'meta-llama/llama-4-scout-17b-16e-instruct',  'meta-llama/llama-4-maverick-17b-128e-instruct',  'qwen-qwq-32b']\n",
    "    \n",
    "    df_model_res =pd.DataFrame(columns=['model_multi_query', 'model_summarizer', 'model_judge', 'abstention_rate', 'accuracy', 'overall_accuracy', 'coverage', 'abstention_rate', 'f1_real', 'f1_fake'])    \n",
    "    df_res = pd.DataFrame(columns=['model_judge','claim', 'verdict_orig','verdict_pred','explanation'])\n",
    "    \n",
    "    for judge_model in models:\n",
    "        model_multi_query = models[0]  # Keep constant\n",
    "        model_summarizer = models[1]   # Keep constant  \n",
    "        model_judge = judge_model      # Test each one\n",
    "        print(f\"Testing with judge: {judge_model}\")\n",
    "    \n",
    "        \n",
    "        df_test = pd.read_csv(train_file_name)\n",
    "        df_test = df_test.head(1)  # Limit to 50 rows for testing\n",
    "        \n",
    "        for index, row in df_test.iterrows():\n",
    "            lis1 = []\n",
    "            claim = row.claim\n",
    "            print(f\"Processing row {index + 1}/{len(df_test)} Using judge model: {judge_model}\")\n",
    "    \n",
    "            claim_final, verdict_class, verdict_full = verify_news(claim,model_multi_query,model_summarizer,model_judge)\n",
    "            lis1 = [model_judge , claim, row.label, verdict_class, verdict_full]\n",
    "        \n",
    "            df_res.loc[len(df_res)] = lis1\n",
    "    \n",
    "        df_res.verdict_orig = df_res.verdict_orig.str.upper()\n",
    "        y_true_labels = df_res['verdict_orig'].tolist()\n",
    "        y_pred_labels = df_res['verdict_pred'].tolist()\n",
    "    \n",
    "        total = len(df_res)\n",
    "    \n",
    "        # Filter each category\n",
    "        TP = len(df_res[(df_res.verdict_orig == \"REAL\") & (df_res.verdict_pred == \"REAL\")])\n",
    "        TN = len(df_res[(df_res.verdict_orig == \"FAKE\") & (df_res.verdict_pred == \"FAKE\")])\n",
    "        FP = len(df_res[(df_res.verdict_orig == \"FAKE\") & (df_res.verdict_pred == \"REAL\")])\n",
    "        FN = len(df_res[(df_res.verdict_orig == \"REAL\") & (df_res.verdict_pred == \"FAKE\")])\n",
    "        U1 = len(df_res[(df_res.verdict_orig == \"REAL\") & (df_res.verdict_pred == \"UNSURE\")])\n",
    "        U2 = len(df_res[(df_res.verdict_orig == \"FAKE\") & (df_res.verdict_pred == \"UNSURE\")])\n",
    "    \n",
    "        # Base metrics\n",
    "        confident_preds = TP + TN + FP + FN\n",
    "        unsure_preds = U1 + U2\n",
    "    \n",
    "        accuracy = (TP + TN) / confident_preds if confident_preds else 0\n",
    "        overall_accuracy = (TP + TN) / total if total else 0\n",
    "        coverage = confident_preds / total\n",
    "        abstention_rate = unsure_preds / total\n",
    "    \n",
    "        # F1 for REAL class\n",
    "        precision_real = TP / (TP + FP) if (TP + FP) else 0\n",
    "        recall_real = TP / (TP + FN) if (TP + FN) else 0\n",
    "        f1_real = 2 * precision_real * recall_real / (precision_real + recall_real) if (precision_real + recall_real) else 0\n",
    "    \n",
    "        # F1 for FAKE class\n",
    "        TP_fake = TN\n",
    "        FP_fake = FN\n",
    "        FN_fake = FP + U2\n",
    "    \n",
    "        precision_fake = TP_fake / (TP_fake + FP_fake) if (TP_fake + FP_fake) else 0\n",
    "        recall_fake = TP_fake / (TP_fake + FN_fake) if (TP_fake + FN_fake) else 0\n",
    "        f1_fake = 2 * precision_fake * recall_fake / (precision_fake + recall_fake) if (precision_fake + recall_fake) else 0\n",
    "    \n",
    "        list_res = [model_multi_query, model_summarizer, judge_model,abstention_rate,accuracy,overall_accuracy,coverage,abstention_rate,f1_real,f1_fake]\n",
    "        df_model_res.loc[len(df_model_res)] = list_res\n",
    "\n",
    "    return df_model_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf5954",
   "metadata": {},
   "source": [
    "Evaluating with Prompt Strategy 1  \n",
    "    \n",
    "    Multi Query RAG  \n",
    "    Summarization  \n",
    "    Judge Prompt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "688e9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import mimetypes\n",
    "import os\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "from sarvamai import SarvamAI\n",
    "import re\n",
    "\n",
    "grok_api_key = os.getenv('GROK_API_KEY')\n",
    "serp_dev_api_key = os.getenv('SERP_DEV_API_KEY')\n",
    "sarvam_api_key = os.getenv('SARVAM_API_KEY')\n",
    "\n",
    "empty_search = None\n",
    "\n",
    "class SerperRetrieverWrapper_1:\n",
    "    #Class to use Serper as retriver agent for the RAG framework\n",
    "    def __init__(self, api_key: str, num_results: int = 15):\n",
    "        self.api_key = api_key\n",
    "        self.num_results = num_results\n",
    "    \n",
    "    def get_relevant_documents(self, query: str):\n",
    "        \"\"\"\n",
    "        Query Serper.dev and return up to `num_results` organic search hits.\n",
    "        Each hit is a dict: { \"title\": str, \"link\": str, \"snippet\": str }.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            _SERPER_SEARCH_URL = \"https://google.serper.dev/news\"\n",
    "            q1 = '(site:news18.com OR site:ptinews.com OR site:politifact.com) ' + query\n",
    "            #print('Serper query: ', q1)\n",
    "    \n",
    "            headers = {\n",
    "                \"X-API-KEY\": self.api_key,\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "            payload = {\n",
    "                \"q\": q1,\n",
    "                \"num\": self.num_results,\n",
    "            }\n",
    "            \n",
    "            resp = requests.post(_SERPER_SEARCH_URL, headers=headers, json=payload)\n",
    "            #print('Serper response: ', resp)\n",
    "            #print('Serper response code: ', resp.json())\n",
    "            \n",
    "            if resp.status_code != 200:\n",
    "                raise Exception(f\"Serper API Error: {resp.text}\")\n",
    "            results = resp.json()\n",
    "            #print('Serper results: ', results.type)\n",
    "\n",
    "            #return results\n",
    "            \n",
    "            documents = []\n",
    "            for i, item in enumerate(results.get(\"news\", []), 1):\n",
    "                title = item.get('title')\n",
    "                link = item.get('link')\n",
    "                snippet = item.get('snippet')\n",
    "                documents.append(Document(\n",
    "                    page_content=f\"{title}\\n{snippet}\",\n",
    "                    metadata={\"source\": link}\n",
    "                ))\n",
    "            \n",
    "            #if not documents:\n",
    "            #    empty_search = Exception(\"No result found\")\n",
    "            #    raise empty_search\n",
    "            \n",
    "            #print(f\"Retrieved {len(documents)} documents from Serper.\")\n",
    "            return documents\n",
    "        except Exception as e:\n",
    "            if e is empty_search:\n",
    "                print('serper main exception1')\n",
    "                raise empty_search\n",
    "            else:\n",
    "                print('serper main exception2')\n",
    "                raise e\n",
    "        \n",
    "def verify_news(user_claim, i_model_multi_query, i_model_summarizer, i_model_judge, input_lang = 'auto'):\n",
    "    \"\"\"\n",
    "       Description: This function is used to verify the claim provided by the user and output as REAL or FAKE or UNSURE based on the context with a short explanation\n",
    "       INPUT: user_claim --> The news user wish to verify\n",
    "       OUTPUT: FAKE/REAL/UNSURE with explanation\n",
    "    \"\"\"\n",
    "    try:\n",
    "       model_multi_query = i_model_multi_query\n",
    "       model_summarizer = i_model_summarizer\n",
    "       model_judge = i_model_judge\n",
    "\n",
    "       #print('here1: ', user_claim)\n",
    "       claim1 = user_claim.replace(\"'\",\"\")\n",
    "       claim1 = user_claim.replace(\"\\n\",\" \")\n",
    "       #print('here2: ', claim1)\n",
    "        \n",
    "       serper_retriever = SerperRetrieverWrapper_1(api_key=serp_dev_api_key)\n",
    "       context_retriever = RunnableLambda(serper_retriever.get_relevant_documents)\n",
    "       \n",
    "       \"\"\"\n",
    "       Implemeting RAG framework with Multi Query Translation\n",
    "       Step 1 -- Take input from user for the news to verify\n",
    "       Step 2 -- Generate 3 variants of the news for better seach results\n",
    "       Step 3 -- Summarise the results from all the previous steps to be passed to main prompt\n",
    "       Step 4 -- Deliver the final verdict with a short explanation\n",
    "       \"\"\"\n",
    "       \n",
    "       #Multi Query Generation\n",
    "       \n",
    "       multi_query_template = \"\"\"\n",
    "            You are an AI language assistant.\n",
    "\n",
    "             Your task is to generate three alternative phrasings of the given user question to help retrieve relevant documents from a vector database. These alternatives should reflect different ways the original question might be asked, using varied vocabulary or structure, while preserving the original intent.             \n",
    "             This helps improve the chances of matching relevant content in a distance-based similarity search.\n",
    "             \n",
    "             Original question: {question}\n",
    "             \n",
    "             Output:\n",
    "             Provide exactly three reworded versions of the question, each on a new line.\n",
    "       \"\"\"\n",
    "       perspectives_prompt = ChatPromptTemplate.from_template(multi_query_template)\n",
    "       \n",
    "       llm_multi_query = ChatGroq(api_key = grok_api_key, model_name = model_multi_query)\n",
    "       \n",
    "       generate_queries = (\n",
    "           perspectives_prompt \n",
    "           | llm_multi_query\n",
    "           | StrOutputParser() \n",
    "           | (lambda x: x.split(\"\\n\"))\n",
    "       )\n",
    "       \n",
    "       #Summarization using multi query\n",
    "       \n",
    "       summarizer_template = '''\n",
    "          You are an assistant summarizing factual evidence from multiple documents.\n",
    "       \n",
    "          Based on the following documents, extract the key facts relevant to the claim.\n",
    "          \n",
    "          Claim: {question}\n",
    "          \n",
    "          Documents:\n",
    "          {context}\n",
    "          \n",
    "          Return a short neutral summary of the key facts only.\n",
    "       '''\n",
    "       summarizer_prompt = PromptTemplate.from_template(summarizer_template)\n",
    "       \n",
    "       llm_summarizer = ChatGroq(api_key = grok_api_key, model_name = model_summarizer)\n",
    "       summarizer_chain = (\n",
    "           {\n",
    "               \"context\": context_retriever,\n",
    "               \"question\": generate_queries\n",
    "           }\n",
    "           | summarizer_prompt\n",
    "           | llm_summarizer\n",
    "           | StrOutputParser()\n",
    "       )\n",
    "       \n",
    "       #Final Judgement \n",
    "       \n",
    "       fact_checker_template = '''\n",
    "          You are a fact-checking assistant. Give a direct answer without showing your thinking process.\n",
    "          \n",
    "          Claim: {question}\n",
    "          \n",
    "          Evidence:\n",
    "          {evidence}\n",
    "          \n",
    "          Instructions:\n",
    "          \n",
    "          If evidence is provided, use only that evidence to determine whether the claim is REAL, FAKE, or UNSURE.          \n",
    "          If no evidence is provided, conduct a brief web search to gather supporting or contradicting information. Prioritize information from reliable, reputable sources such as news websites, fact-checking organizations, or official statements.\n",
    "          \n",
    "          If no sufficient or conclusive evidence is found from these sources, respond with UNSURE.          \n",
    "          Do not speculate or rely on untrusted sources.\n",
    "\n",
    "          Respond in this format:\n",
    "          \n",
    "          Classification: REAL / FAKE / UNSURE  \n",
    "          Explanation: <Your reasoning, clearly supported by the evidence or source content> \n",
    "       '''\n",
    "       \n",
    "       fact_checker_prompt = PromptTemplate.from_template(fact_checker_template)\n",
    "       \n",
    "       llm_fact_checker = ChatGroq(api_key = grok_api_key, model_name = model_judge)\n",
    "       fact_checker_chain = (\n",
    "           {\n",
    "               \"question\": RunnablePassthrough(),\n",
    "               \"evidence\": summarizer_chain \n",
    "           }\n",
    "           | fact_checker_prompt\n",
    "           | llm_fact_checker\n",
    "           | StrOutputParser()\n",
    "       )\n",
    "   \n",
    "       claim = claim1\n",
    "       \n",
    "       #Calling SARVAM API to translate Indic languages to English\n",
    "       client = SarvamAI(api_subscription_key = sarvam_api_key)\n",
    "       \n",
    "       try:\n",
    "           translation = client.text.translate(\n",
    "           input=claim,\n",
    "           source_language_code=\"auto\",\n",
    "           target_language_code=\"en-IN\"\n",
    "           )\n",
    "       except Exception as e:\n",
    "           print(f\"Error during translation: {e}\")\n",
    "           error_msg = 'It appears you have provided input in an alien language. Please try again with some other language'\n",
    "           return error_msg,error_msg,error_msg\n",
    "       \n",
    "       claim_final = translation.translated_text if translation else claim\n",
    "       claim_orig_lang = translation.source_language_code\n",
    "       #print(f\"Translated claim: {claim_final}\")\n",
    "       \n",
    "       verdict_orig = fact_checker_chain.invoke(claim_final)\n",
    "       verdict_class = verdict_orig.split('\\n')[0]\n",
    "       verdict_explan = verdict_orig.split('\\n')[-1]\n",
    "\n",
    "       # Strip out any <think> or <tool> or similar tags\n",
    "       cleaned_output = re.sub(r\"<[^>]+>\", \"\", verdict_orig).strip()\n",
    "       \n",
    "       verdict_class = re.search(r'Classification:\\s*(REAL|FAKE|UNSURE)', cleaned_output)\n",
    "       verdict_explan = re.search(r'Explanation:\\s*(.*)', cleaned_output, re.DOTALL)\n",
    "       \n",
    "       verdict_class = verdict_class.group(1) if verdict_class else \"UNSURE\"\n",
    "       verdict_explan = verdict_explan.group(1).strip() if verdict_explan else \"No clear explanation found.\"\n",
    "\n",
    "       #print('here1: ',verdict_class)\n",
    "       #print('here2: ',verdict_explan)\n",
    "       \n",
    "       if input_lang == 'auto':\n",
    "           trans_lang = claim_orig_lang\n",
    "       else:\n",
    "           trans_lang = input_lang\n",
    "   \n",
    "       if claim_orig_lang != 'en-IN':\n",
    "           try:\n",
    "               translation_class = client.text.translate(\n",
    "               input=verdict_class,\n",
    "               source_language_code='en-IN',\n",
    "               target_language_code=claim_orig_lang\n",
    "               )\n",
    "           except Exception as e:\n",
    "               print(f\"Error during verdict translation: {e}\")  \n",
    "               error_msg = 'Something went wrong while translating the verdict. Please try again'\n",
    "               return error_msg,error_msg,error_msg\n",
    "               \n",
    "           try:\n",
    "               translation_explan = client.text.translate(\n",
    "               input=verdict_explan,\n",
    "               source_language_code='en-IN',\n",
    "               target_language_code=claim_orig_lang\n",
    "               )\n",
    "           except Exception as e:\n",
    "               print(f\"Error during verdict translation: {e}\")  \n",
    "               error_msg = 'Something went wrong while translating the verdict. Please try again'\n",
    "               return error_msg,error_msg,error_msg\n",
    "           \n",
    "           verdict_trans_class = translation_class.translated_text\n",
    "           verdict_trans_explan = translation_explan.translated_text\n",
    "           verdict_trans = verdict_trans_class + '\\n\\n' + verdict_trans_explan\n",
    "           \n",
    "           verdict_orig = verdict_class + '\\n\\n' + verdict_explan\n",
    "       else:\n",
    "           verdict_orig = verdict_class + '\\n\\n' + verdict_explan\n",
    "           verdict_trans_class = verdict_class\n",
    "           verdict_trans_explan = verdict_explan\n",
    "           verdict_trans = verdict_trans_class + '\\n\\n' + verdict_trans_explan\n",
    "           #print('verdict_orig: ', verdict_orig) \n",
    "           \n",
    "           try:\n",
    "               match = re.search(r':(.*)', verdict_class)\n",
    "               if match:\n",
    "                    verdict1 = match.group(1).strip()\n",
    "                    #print(verdict1)\n",
    "           except Exception as e:\n",
    "               print('here3')\n",
    "               verdict1 = verdict_class\n",
    "       \n",
    "       #return(claim_final, verdict_orig, verdict_trans)\n",
    "       return(claim_final, verdict_class, verdict_orig)\n",
    "    except Exception as e:\n",
    "        if str(e) == 'No result found':\n",
    "            print('Error in main proc1. Error is ', e)\n",
    "            error_msg = 'The search for this claim came back empty. Please rephrase the claim or try with a new one'\n",
    "            return('UNSURE' ,error_msg,error_msg)\n",
    "        else:\n",
    "            print('Error in main proc2. Error is ', e)\n",
    "            error_msg = 'Something went wrong. Please try after some time'\n",
    "            return(error_msg,error_msg,error_msg)\n",
    "    \n",
    "def transcribe_audio(audio):\n",
    "    \"\"\"\n",
    "       Description: This function trascibes audio using SarvamAI STT model \n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = SarvamAI(api_subscription_key = sarvam_api_key)\n",
    "        mime_type, _ = mimetypes.guess_type(audio)\n",
    "        \n",
    "        with open(audio, \"rb\") as f:\n",
    "            response = client.speech_to_text.transcribe(\n",
    "                file=(\"audio.mp3\", f, mime_type or \"audio/mpeg\"),\n",
    "                model=\"saarika:v2.5\",\n",
    "                language_code=\"unknown\"\n",
    "            )\n",
    "        ret_var = response.transcript\n",
    "        ret_lang = response.language_code\n",
    "    except Exception as e:\n",
    "        print(f\"Error during translation: {e}\")\n",
    "        ret_var = ''\n",
    "\n",
    "    return ret_var, ret_lang\n",
    "    \n",
    "def verify_news_audio(audio):\n",
    "    \"\"\"\n",
    "       Description: This function verifies the news where input method is Audio\n",
    "    \"\"\"\n",
    "    \n",
    "    claim, orig_lang = transcribe_audio(audio)\n",
    "    if claim == '':\n",
    "        error_msg = 'I could not understand your message. Please try recording again'\n",
    "        return(error_msg,error_msg,error_msg)\n",
    "    \n",
    "    final_claim, verdict, verdict_trans = verify_news(claim, orig_lang)\n",
    "    return final_claim, verdict, verdict_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strategy_1 = model_evaluate()\n",
    "df_strategy_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c0b96",
   "metadata": {},
   "source": [
    "Evaluating with Prompt Strategy 2\n",
    "    \n",
    "    Multi Query RAG    \n",
    "    Judge Prompt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "603a87d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import mimetypes\n",
    "import os\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "from sarvamai import SarvamAI\n",
    "import re\n",
    "\n",
    "grok_api_key = os.getenv('GROK_API_KEY')\n",
    "serp_dev_api_key = os.getenv('SERP_DEV_API_KEY')\n",
    "sarvam_api_key = os.getenv('SARVAM_API_KEY')\n",
    "\n",
    "\n",
    "empty_search = None\n",
    "\n",
    "class SerperRetrieverWrapper_2:\n",
    "    #Class to use Serper as retriver agent for the RAG framework\n",
    "    def __init__(self, api_key: str, num_results: int = 15):\n",
    "        self.api_key = api_key\n",
    "        self.num_results = num_results\n",
    "    \n",
    "    def get_relevant_documents(self, query: str):\n",
    "        \"\"\"\n",
    "        Query Serper.dev and return up to `num_results` organic search hits.\n",
    "        Each hit is a dict: { \"title\": str, \"link\": str, \"snippet\": str }.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            _SERPER_SEARCH_URL = \"https://google.serper.dev/news\"\n",
    "            q1 = '(site:news18.com OR site:ptinews.com OR site:politifact.com) ' + query\n",
    "            #print('Serper query: ', q1)\n",
    "    \n",
    "            headers = {\n",
    "                \"X-API-KEY\": self.api_key,\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "            payload = {\n",
    "                \"q\": q1,\n",
    "                \"num\": self.num_results,\n",
    "            }\n",
    "            \n",
    "            resp = requests.post(_SERPER_SEARCH_URL, headers=headers, json=payload)\n",
    "            #print('Serper response: ', resp)\n",
    "            #print('Serper response code: ', resp.json())\n",
    "            \n",
    "            if resp.status_code != 200:\n",
    "                raise Exception(f\"Serper API Error: {resp.text}\")\n",
    "            results = resp.json()\n",
    "            #print('Serper results: ', results.type)\n",
    "\n",
    "            #return results\n",
    "            \n",
    "            documents = []\n",
    "            for i, item in enumerate(results.get(\"news\", []), 1):\n",
    "                title = item.get('title')\n",
    "                link = item.get('link')\n",
    "                snippet = item.get('snippet')\n",
    "                documents.append(Document(\n",
    "                    page_content=f\"{title}\\n{snippet}\",\n",
    "                    metadata={\"source\": link}\n",
    "                ))\n",
    "            \n",
    "            #if not documents:\n",
    "            #    empty_search = Exception(\"No result found\")\n",
    "            #    raise empty_search\n",
    "            \n",
    "            #print(f\"Retrieved {len(documents)} documents from Serper.\")\n",
    "            return documents\n",
    "        except Exception as e:\n",
    "            if e is empty_search:\n",
    "                print('serper main exception1')\n",
    "                raise empty_search\n",
    "            else:\n",
    "                print('serper main exception2')\n",
    "                raise e\n",
    "        \n",
    "def verify_news(user_claim, i_model_multi_query, i_model_summarizer, i_model_judge, input_lang = 'auto'):\n",
    "    \"\"\"\n",
    "       Description: This function is used to verify the claim provided by the user and output as REAL or FAKE or UNSURE based on the context with a short explanation\n",
    "       INPUT: user_claim --> The news user wish to verify\n",
    "       OUTPUT: FAKE/REAL/UNSURE with explanation\n",
    "    \"\"\"\n",
    "    try:\n",
    "       model_multi_query = i_model_multi_query\n",
    "       model_summarizer = i_model_summarizer\n",
    "       model_judge = i_model_judge\n",
    "\n",
    "       #print('here1: ', user_claim)\n",
    "       claim1 = user_claim.replace(\"'\",\"\")\n",
    "       claim1 = claim1.replace(\"\\n\",\" \")\n",
    "       #print('here2: ', claim1)\n",
    "        \n",
    "       serper_retriever = SerperRetrieverWrapper_2(api_key=serp_dev_api_key)\n",
    "       context_retriever = RunnableLambda(serper_retriever.get_relevant_documents)\n",
    "       \n",
    "       \"\"\"\n",
    "       Implemeting RAG framework with Multi Query Translation\n",
    "       Step 1 -- Take input from user for the news to verify\n",
    "       Step 2 -- Generate 3 variants of the news for better seach results\n",
    "       Step 3 -- Summarise the results from all the previous steps to be passed to main prompt\n",
    "       Step 4 -- Deliver the final verdict with a short explanation\n",
    "       \"\"\"\n",
    "       \n",
    "       #Multi Query Generation\n",
    "       \n",
    "       multi_query_template = \"\"\"\n",
    "            You are an AI language assistant.\n",
    "\n",
    "             Your task is to generate three alternative phrasings of the given user question to help retrieve relevant documents from a vector database. These alternatives should reflect different ways the original question might be asked, using varied vocabulary or structure, while preserving the original intent.             \n",
    "             This helps improve the chances of matching relevant content in a distance-based similarity search.\n",
    "             \n",
    "             Original question: {question}\n",
    "             \n",
    "             Output:\n",
    "             Provide exactly three reworded versions of the question, each on a new line.\n",
    "       \"\"\"\n",
    "       perspectives_prompt = ChatPromptTemplate.from_template(multi_query_template)\n",
    "       \n",
    "       llm_multi_query = ChatGroq(api_key = grok_api_key, model_name = model_multi_query)\n",
    "       \n",
    "       generate_queries = (\n",
    "           perspectives_prompt \n",
    "           | llm_multi_query\n",
    "           | StrOutputParser() \n",
    "           | (lambda x: x.split(\"\\n\"))\n",
    "       )\n",
    "       \n",
    "       \"\"\"\n",
    "       #Summarization using multi query\n",
    "       \n",
    "       summarizer_template = '''\n",
    "          You are an assistant summarizing factual evidence from multiple documents.\n",
    "       \n",
    "          Based on the following documents, extract the key facts relevant to the claim.\n",
    "          \n",
    "          Claim: {question}\n",
    "          \n",
    "          Documents:\n",
    "          {context}\n",
    "          \n",
    "          Return a short neutral summary of the key facts only.\n",
    "       '''\n",
    "       summarizer_prompt = PromptTemplate.from_template(summarizer_template)\n",
    "       \n",
    "       llm_summarizer = ChatGroq(api_key = grok_api_key, model_name = model_summarizer)\n",
    "       summarizer_chain = (\n",
    "           {\n",
    "               \"context\": context_retriever,\n",
    "               \"question\": generate_queries\n",
    "           }\n",
    "           | summarizer_prompt\n",
    "           | llm_summarizer\n",
    "           | StrOutputParser()\n",
    "       )\n",
    "       \"\"\"\n",
    "       \n",
    "       #Final Judgement \n",
    "       \n",
    "       fact_checker_template = '''\n",
    "          You are a fact-checking assistant.\n",
    "          \n",
    "          Claim: {question}\n",
    "          \n",
    "          Evidence:\n",
    "          {evidence}\n",
    "          \n",
    "          Instructions:\n",
    "          \n",
    "          If evidence is provided, use only that evidence to determine whether the claim is REAL, FAKE, or UNSURE.          \n",
    "          \n",
    "          If no sufficient or conclusive evidence is found from these sources, respond with UNSURE.          \n",
    "          Do not speculate or rely on untrusted sources.\n",
    "\n",
    "          Respond in this format:\n",
    "          \n",
    "          Classification: REAL / FAKE / UNSURE  \n",
    "          Explanation: <Your reasoning, clearly supported by the evidence or source content> \n",
    "       '''\n",
    "       \n",
    "       fact_checker_prompt = PromptTemplate.from_template(fact_checker_template)\n",
    "       \n",
    "       llm_fact_checker = ChatGroq(api_key = grok_api_key, model_name = model_judge)\n",
    "       fact_checker_chain = (\n",
    "           {\n",
    "               \"question\": RunnablePassthrough(),\n",
    "               \"evidence\": context_retriever \n",
    "           }\n",
    "           | fact_checker_prompt\n",
    "           | llm_fact_checker\n",
    "           | StrOutputParser()\n",
    "       )\n",
    "   \n",
    "       claim = claim1\n",
    "       \n",
    "       #Calling SARVAM API to translate Indic languages to English\n",
    "       client = SarvamAI(api_subscription_key = sarvam_api_key)\n",
    "       \n",
    "       try:\n",
    "           translation = client.text.translate(\n",
    "           input=claim,\n",
    "           source_language_code=\"auto\",\n",
    "           target_language_code=\"en-IN\"\n",
    "           )\n",
    "       except Exception as e:\n",
    "           print(f\"Error during translation: {e}\")\n",
    "           error_msg = 'It appears you have provided input in an alien language. Please try again with some other language'\n",
    "           return error_msg,error_msg,error_msg\n",
    "       \n",
    "       claim_final = translation.translated_text if translation else claim\n",
    "       claim_orig_lang = translation.source_language_code\n",
    "       #print(f\"Translated claim: {claim_final}\")\n",
    "       \n",
    "       verdict_orig = fact_checker_chain.invoke(claim_final)\n",
    "       verdict_class = verdict_orig.split('\\n')[0]\n",
    "       verdict_explan = verdict_orig.split('\\n')[-1]\n",
    "\n",
    "       # Strip out any <think> or <tool> or similar tags\n",
    "       cleaned_output = re.sub(r\"<[^>]+>\", \"\", verdict_orig).strip()\n",
    "       \n",
    "       verdict_class = re.search(r'Classification:\\s*(REAL|FAKE|UNSURE)', cleaned_output)\n",
    "       verdict_explan = re.search(r'Explanation:\\s*(.*)', cleaned_output, re.DOTALL)\n",
    "       \n",
    "       verdict_class = verdict_class.group(1) if verdict_class else \"UNSURE\"\n",
    "       verdict_explan = verdict_explan.group(1).strip() if verdict_explan else \"No clear explanation found.\"\n",
    "\n",
    "       #print('here1: ',verdict_class)\n",
    "       #print('here2: ',verdict_explan)\n",
    "       \n",
    "       if input_lang == 'auto':\n",
    "           trans_lang = claim_orig_lang\n",
    "       else:\n",
    "           trans_lang = input_lang\n",
    "   \n",
    "       if claim_orig_lang != 'en-IN':\n",
    "           try:\n",
    "               translation_class = client.text.translate(\n",
    "               input=verdict_class,\n",
    "               source_language_code='en-IN',\n",
    "               target_language_code=claim_orig_lang\n",
    "               )\n",
    "           except Exception as e:\n",
    "               print(f\"Error during verdict translation: {e}\")  \n",
    "               error_msg = 'Something went wrong while translating the verdict. Please try again'\n",
    "               return error_msg,error_msg,error_msg\n",
    "               \n",
    "           try:\n",
    "               translation_explan = client.text.translate(\n",
    "               input=verdict_explan,\n",
    "               source_language_code='en-IN',\n",
    "               target_language_code=claim_orig_lang\n",
    "               )\n",
    "           except Exception as e:\n",
    "               print(f\"Error during verdict translation: {e}\")  \n",
    "               error_msg = 'Something went wrong while translating the verdict. Please try again'\n",
    "               return error_msg,error_msg,error_msg\n",
    "           \n",
    "           verdict_trans_class = translation_class.translated_text\n",
    "           verdict_trans_explan = translation_explan.translated_text\n",
    "           verdict_trans = verdict_trans_class + '\\n\\n' + verdict_trans_explan\n",
    "           \n",
    "           verdict_orig = verdict_class + '\\n\\n' + verdict_explan\n",
    "       else:\n",
    "           verdict_orig = verdict_class + '\\n\\n' + verdict_explan\n",
    "           verdict_trans_class = verdict_class\n",
    "           verdict_trans_explan = verdict_explan\n",
    "           verdict_trans = verdict_trans_class + '\\n\\n' + verdict_trans_explan\n",
    "           #print('verdict_orig: ', verdict_orig) \n",
    "           \n",
    "           try:\n",
    "               match = re.search(r':(.*)', verdict_class)\n",
    "               if match:\n",
    "                    verdict1 = match.group(1).strip()\n",
    "                    #print(verdict1)\n",
    "           except Exception as e:\n",
    "               print('here3')\n",
    "               verdict1 = verdict_class\n",
    "       \n",
    "       #return(claim_final, verdict_orig, verdict_trans)\n",
    "       return(claim_final, verdict_class, verdict_orig)\n",
    "    except Exception as e:\n",
    "        if str(e) == 'No result found':\n",
    "            print('Error in main proc1. Error is ', e)\n",
    "            error_msg = 'The search for this claim came back empty. Please rephrase the claim or try with a new one'\n",
    "            return('UNSURE' ,error_msg,error_msg)\n",
    "        else:\n",
    "            print('Error in main proc2. Error is ', e)\n",
    "            error_msg = 'Something went wrong. Please try after some time'\n",
    "            return(error_msg,error_msg,error_msg)\n",
    "    \n",
    "def transcribe_audio(audio):\n",
    "    \"\"\"\n",
    "       Description: This function trascibes audio using SarvamAI STT model \n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = SarvamAI(api_subscription_key = sarvam_api_key)\n",
    "        mime_type, _ = mimetypes.guess_type(audio)\n",
    "        \n",
    "        with open(audio, \"rb\") as f:\n",
    "            response = client.speech_to_text.transcribe(\n",
    "                file=(\"audio.mp3\", f, mime_type or \"audio/mpeg\"),\n",
    "                model=\"saarika:v2.5\",\n",
    "                language_code=\"unknown\"\n",
    "            )\n",
    "        ret_var = response.transcript\n",
    "        ret_lang = response.language_code\n",
    "    except Exception as e:\n",
    "        print(f\"Error during translation: {e}\")\n",
    "        ret_var = ''\n",
    "\n",
    "    return ret_var, ret_lang\n",
    "    \n",
    "def verify_news_audio(audio):\n",
    "    \"\"\"\n",
    "       Description: This function verifies the news where input method is Audio\n",
    "    \"\"\"\n",
    "    \n",
    "    claim, orig_lang = transcribe_audio(audio)\n",
    "    if claim == '':\n",
    "        error_msg = 'I could not understand your message. Please try recording again'\n",
    "        return(error_msg,error_msg,error_msg)\n",
    "    \n",
    "    final_claim, verdict, verdict_trans = verify_news(claim, orig_lang)\n",
    "    return final_claim, verdict, verdict_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98368158",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strategy_2 = model_evaluate()\n",
    "df_strategy_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee77cb",
   "metadata": {},
   "source": [
    "Evaluating with Prompt Strategy 3\n",
    "    \n",
    "    Vanilla RAG  \n",
    "    Summarization  \n",
    "    Judge Prompt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5827e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import mimetypes\n",
    "import os\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "from sarvamai import SarvamAI\n",
    "import re\n",
    "\n",
    "grok_api_key = os.getenv('GROK_API_KEY')\n",
    "serp_dev_api_key = os.getenv('SERP_DEV_API_KEY')\n",
    "sarvam_api_key = os.getenv('SARVAM_API_KEY')\n",
    "\n",
    "empty_search = None\n",
    "\n",
    "class SerperRetrieverWrapper_3:\n",
    "    #Class to use Serper as retriver agent for the RAG framework\n",
    "    def __init__(self, api_key: str, num_results: int = 15):\n",
    "        self.api_key = api_key\n",
    "        self.num_results = num_results\n",
    "    \n",
    "    def get_relevant_documents(self, query: str):\n",
    "        \"\"\"\n",
    "        Query Serper.dev and return up to `num_results` organic search hits.\n",
    "        Each hit is a dict: { \"title\": str, \"link\": str, \"snippet\": str }.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            _SERPER_SEARCH_URL = \"https://google.serper.dev/news\"\n",
    "            q1 = '(site:news18.com OR site:ptinews.com OR site:politifact.com) ' + query\n",
    "            #print('Serper query: ', q1)\n",
    "    \n",
    "            headers = {\n",
    "                \"X-API-KEY\": self.api_key,\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "            payload = {\n",
    "                \"q\": q1,\n",
    "                \"num\": self.num_results,\n",
    "            }\n",
    "            \n",
    "            resp = requests.post(_SERPER_SEARCH_URL, headers=headers, json=payload)\n",
    "            #print('Serper response: ', resp)\n",
    "            #print('Serper response code: ', resp.json())\n",
    "            \n",
    "            if resp.status_code != 200:\n",
    "                raise Exception(f\"Serper API Error: {resp.text}\")\n",
    "            results = resp.json()\n",
    "            #print('Serper results: ', results.type)\n",
    "\n",
    "            #return results\n",
    "            \n",
    "            documents = []\n",
    "            for i, item in enumerate(results.get(\"news\", []), 1):\n",
    "                title = item.get('title')\n",
    "                link = item.get('link')\n",
    "                snippet = item.get('snippet')\n",
    "                documents.append(Document(\n",
    "                    page_content=f\"{title}\\n{snippet}\",\n",
    "                    metadata={\"source\": link}\n",
    "                ))\n",
    "            \n",
    "            #if not documents:\n",
    "            #    empty_search = Exception(\"No result found\")\n",
    "            #    raise empty_search\n",
    "            \n",
    "            #print(f\"Retrieved {len(documents)} documents from Serper.\")\n",
    "            return documents\n",
    "        except Exception as e:\n",
    "            if e is empty_search:\n",
    "                print('serper main exception1')\n",
    "                raise empty_search\n",
    "            else:\n",
    "                print('serper main exception2')\n",
    "                raise e\n",
    "        \n",
    "def verify_news(user_claim, i_model_multi_query, i_model_summarizer, i_model_judge, input_lang = 'auto'):\n",
    "    \"\"\"\n",
    "       Description: This function is used to verify the claim provided by the user and output as REAL or FAKE or UNSURE based on the context with a short explanation\n",
    "       INPUT: user_claim --> The news user wish to verify\n",
    "       OUTPUT: FAKE/REAL/UNSURE with explanation\n",
    "    \"\"\"\n",
    "    try:\n",
    "       model_multi_query = i_model_multi_query\n",
    "       model_summarizer = i_model_summarizer\n",
    "       model_judge = i_model_judge\n",
    "\n",
    "       #print('here1: ', user_claim)\n",
    "       claim1 = user_claim.replace(\"'\",\"\")\n",
    "       claim1 = user_claim.replace(\"\\n\",\" \")\n",
    "       #print('here2: ', claim1)\n",
    "        \n",
    "       serper_retriever = SerperRetrieverWrapper_3(api_key=serp_dev_api_key)\n",
    "       context_retriever = RunnableLambda(serper_retriever.get_relevant_documents)\n",
    "       \n",
    "       \"\"\"\n",
    "       Implemeting RAG framework with Multi Query Translation\n",
    "       Step 1 -- Take input from user for the news to verify\n",
    "       Step 2 -- Generate 3 variants of the news for better seach results\n",
    "       Step 3 -- Summarise the results from all the previous steps to be passed to main prompt\n",
    "       Step 4 -- Deliver the final verdict with a short explanation\n",
    "       \"\"\"\n",
    "       \n",
    "       '''\n",
    "       #Multi Query Generation\n",
    "       \n",
    "       multi_query_template = \"\"\"\n",
    "            You are an AI language assistant.\n",
    "       \n",
    "             Your task is to generate three alternative phrasings of the given user question to help retrieve relevant documents from a vector database. These alternatives should reflect different ways the original question might be asked, using varied vocabulary or structure, while preserving the original intent.             \n",
    "             This helps improve the chances of matching relevant content in a distance-based similarity search.\n",
    "             \n",
    "             Original question: {question}\n",
    "             \n",
    "             Output:\n",
    "             Provide exactly three reworded versions of the question, each on a new line.\n",
    "       \"\"\"\n",
    "       perspectives_prompt = ChatPromptTemplate.from_template(multi_query_template)\n",
    "       \n",
    "       llm_multi_query = ChatGroq(api_key = grok_api_key, model_name = model_multi_query)\n",
    "       \n",
    "       generate_queries = (\n",
    "           perspectives_prompt \n",
    "           | llm_multi_query\n",
    "           | StrOutputParser() \n",
    "           | (lambda x: x.split(\"\\n\"))\n",
    "       )\n",
    "       '''\n",
    "       #Summarization using multi query\n",
    "       \n",
    "       summarizer_template = '''\n",
    "          You are an assistant summarizing factual evidence from multiple documents.\n",
    "       \n",
    "          Based on the following documents, extract the key facts relevant to the claim.\n",
    "          \n",
    "          Claim: {question}\n",
    "          \n",
    "          Documents:\n",
    "          {context}\n",
    "          \n",
    "          Return a short neutral summary of the key facts only.\n",
    "       '''\n",
    "       summarizer_prompt = PromptTemplate.from_template(summarizer_template)\n",
    "       \n",
    "       llm_summarizer = ChatGroq(api_key = grok_api_key, model_name = model_summarizer)\n",
    "       summarizer_chain = (\n",
    "           {\n",
    "               \"context\": context_retriever,\n",
    "               \"question\": RunnablePassthrough()\n",
    "           }\n",
    "           | summarizer_prompt\n",
    "           | llm_summarizer\n",
    "           | StrOutputParser()\n",
    "       )\n",
    "       \n",
    "       #Final Judgement \n",
    "       \n",
    "       fact_checker_template = '''\n",
    "          You are a fact-checking assistant. Give a direct answer without showing your thinking process.\n",
    "          \n",
    "          Claim: {question}\n",
    "          \n",
    "          Evidence:\n",
    "          {evidence}\n",
    "          \n",
    "          Instructions:\n",
    "          \n",
    "          If evidence is provided, use only that evidence to determine whether the claim is REAL, FAKE, or UNSURE.          \n",
    "          If no evidence is provided, conduct a brief web search to gather supporting or contradicting information. Prioritize information from reliable, reputable sources such as news websites, fact-checking organizations, or official statements.\n",
    "          \n",
    "          If no sufficient or conclusive evidence is found from these sources, respond with UNSURE.          \n",
    "          Do not speculate or rely on untrusted sources.\n",
    "\n",
    "          Respond in this format:\n",
    "          \n",
    "          Classification: REAL / FAKE / UNSURE  \n",
    "          Explanation: <Your reasoning, clearly supported by the evidence or source content> \n",
    "       '''\n",
    "       \n",
    "       fact_checker_prompt = PromptTemplate.from_template(fact_checker_template)\n",
    "       \n",
    "       llm_fact_checker = ChatGroq(api_key = grok_api_key, model_name = model_judge)\n",
    "       fact_checker_chain = (\n",
    "           {\n",
    "               \"question\": RunnablePassthrough(),\n",
    "               \"evidence\": summarizer_chain \n",
    "           }\n",
    "           | fact_checker_prompt\n",
    "           | llm_fact_checker\n",
    "           | StrOutputParser()\n",
    "       )\n",
    "   \n",
    "       claim = claim1\n",
    "       \n",
    "       #Calling SARVAM API to translate Indic languages to English\n",
    "       client = SarvamAI(api_subscription_key = sarvam_api_key)\n",
    "       \n",
    "       try:\n",
    "           translation = client.text.translate(\n",
    "           input=claim,\n",
    "           source_language_code=\"auto\",\n",
    "           target_language_code=\"en-IN\"\n",
    "           )\n",
    "       except Exception as e:\n",
    "           print(f\"Error during translation: {e}\")\n",
    "           error_msg = 'It appears you have provided input in an alien language. Please try again with some other language'\n",
    "           return error_msg,error_msg,error_msg\n",
    "       \n",
    "       claim_final = translation.translated_text if translation else claim\n",
    "       claim_orig_lang = translation.source_language_code\n",
    "       #print(f\"Translated claim: {claim_final}\")\n",
    "       \n",
    "       verdict_orig = fact_checker_chain.invoke(claim_final)\n",
    "       verdict_class = verdict_orig.split('\\n')[0]\n",
    "       verdict_explan = verdict_orig.split('\\n')[-1]\n",
    "\n",
    "       # Strip out any <think> or <tool> or similar tags\n",
    "       cleaned_output = re.sub(r\"<[^>]+>\", \"\", verdict_orig).strip()\n",
    "       \n",
    "       verdict_class = re.search(r'Classification:\\s*(REAL|FAKE|UNSURE)', cleaned_output)\n",
    "       verdict_explan = re.search(r'Explanation:\\s*(.*)', cleaned_output, re.DOTALL)\n",
    "       \n",
    "       verdict_class = verdict_class.group(1) if verdict_class else \"UNSURE\"\n",
    "       verdict_explan = verdict_explan.group(1).strip() if verdict_explan else \"No clear explanation found.\"\n",
    "\n",
    "       #print('here1: ',verdict_class)\n",
    "       #print('here2: ',verdict_explan)\n",
    "       \n",
    "       if input_lang == 'auto':\n",
    "           trans_lang = claim_orig_lang\n",
    "       else:\n",
    "           trans_lang = input_lang\n",
    "   \n",
    "       if claim_orig_lang != 'en-IN':\n",
    "           try:\n",
    "               translation_class = client.text.translate(\n",
    "               input=verdict_class,\n",
    "               source_language_code='en-IN',\n",
    "               target_language_code=claim_orig_lang\n",
    "               )\n",
    "           except Exception as e:\n",
    "               print(f\"Error during verdict translation: {e}\")  \n",
    "               error_msg = 'Something went wrong while translating the verdict. Please try again'\n",
    "               return error_msg,error_msg,error_msg\n",
    "               \n",
    "           try:\n",
    "               translation_explan = client.text.translate(\n",
    "               input=verdict_explan,\n",
    "               source_language_code='en-IN',\n",
    "               target_language_code=claim_orig_lang\n",
    "               )\n",
    "           except Exception as e:\n",
    "               print(f\"Error during verdict translation: {e}\")  \n",
    "               error_msg = 'Something went wrong while translating the verdict. Please try again'\n",
    "               return error_msg,error_msg,error_msg\n",
    "           \n",
    "           verdict_trans_class = translation_class.translated_text\n",
    "           verdict_trans_explan = translation_explan.translated_text\n",
    "           verdict_trans = verdict_trans_class + '\\n\\n' + verdict_trans_explan\n",
    "           \n",
    "           verdict_orig = verdict_class + '\\n\\n' + verdict_explan\n",
    "       else:\n",
    "           verdict_orig = verdict_class + '\\n\\n' + verdict_explan\n",
    "           verdict_trans_class = verdict_class\n",
    "           verdict_trans_explan = verdict_explan\n",
    "           verdict_trans = verdict_trans_class + '\\n\\n' + verdict_trans_explan\n",
    "           #print('verdict_orig: ', verdict_orig) \n",
    "           \n",
    "           try:\n",
    "               match = re.search(r':(.*)', verdict_class)\n",
    "               if match:\n",
    "                    verdict1 = match.group(1).strip()\n",
    "                    #print(verdict1)\n",
    "           except Exception as e:\n",
    "               print('here3')\n",
    "               verdict1 = verdict_class\n",
    "       \n",
    "       #return(claim_final, verdict_orig, verdict_trans)\n",
    "       return(claim_final, verdict_class, verdict_orig)\n",
    "    except Exception as e:\n",
    "        if str(e) == 'No result found':\n",
    "            print('Error in main proc1. Error is ', e)\n",
    "            error_msg = 'The search for this claim came back empty. Please rephrase the claim or try with a new one'\n",
    "            return('UNSURE' ,error_msg,error_msg)\n",
    "        else:\n",
    "            print('Error in main proc2. Error is ', e)\n",
    "            error_msg = 'Something went wrong. Please try after some time'\n",
    "            return(error_msg,error_msg,error_msg)\n",
    "    \n",
    "def transcribe_audio(audio):\n",
    "    \"\"\"\n",
    "       Description: This function trascibes audio using SarvamAI STT model \n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = SarvamAI(api_subscription_key = sarvam_api_key)\n",
    "        mime_type, _ = mimetypes.guess_type(audio)\n",
    "        \n",
    "        with open(audio, \"rb\") as f:\n",
    "            response = client.speech_to_text.transcribe(\n",
    "                file=(\"audio.mp3\", f, mime_type or \"audio/mpeg\"),\n",
    "                model=\"saarika:v2.5\",\n",
    "                language_code=\"unknown\"\n",
    "            )\n",
    "        ret_var = response.transcript\n",
    "        ret_lang = response.language_code\n",
    "    except Exception as e:\n",
    "        print(f\"Error during translation: {e}\")\n",
    "        ret_var = ''\n",
    "\n",
    "    return ret_var, ret_lang\n",
    "    \n",
    "def verify_news_audio(audio):\n",
    "    \"\"\"\n",
    "       Description: This function verifies the news where input method is Audio\n",
    "    \"\"\"\n",
    "    \n",
    "    claim, orig_lang = transcribe_audio(audio)\n",
    "    if claim == '':\n",
    "        error_msg = 'I could not understand your message. Please try recording again'\n",
    "        return(error_msg,error_msg,error_msg)\n",
    "    \n",
    "    final_claim, verdict, verdict_trans = verify_news(claim, orig_lang)\n",
    "    return final_claim, verdict, verdict_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812628b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strategy_3 = model_evaluate()\n",
    "df_strategy_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0778e9d",
   "metadata": {},
   "source": [
    "Evaulating with Regional languages using Prompt Strategy 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3609ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import mimetypes\n",
    "import os\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "from sarvamai import SarvamAI\n",
    "import re\n",
    "\n",
    "empty_search = None\n",
    "\n",
    "class SerperRetrieverWrapper:\n",
    "    #Class to use Serper as retriver agent for the RAG framework\n",
    "    def __init__(self, api_key: str, num_results: int = 15):\n",
    "        self.api_key = api_key\n",
    "        self.num_results = num_results\n",
    "    \n",
    "    def get_relevant_documents(self, query: str):\n",
    "        \"\"\"\n",
    "        Query Serper.dev and return up to `num_results` organic search hits.\n",
    "        Each hit is a dict: { \"title\": str, \"link\": str, \"snippet\": str }.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            _SERPER_SEARCH_URL = \"https://google.serper.dev/news\"\n",
    "            q1 = '(site:news18.com OR site:ptinews.com OR site:politifact.com) ' + query\n",
    "            #print('Serper query: ', q1)\n",
    "    \n",
    "            headers = {\n",
    "                \"X-API-KEY\": self.api_key,\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "            payload = {\n",
    "                \"q\": q1,\n",
    "                \"num\": self.num_results,\n",
    "            }\n",
    "            \n",
    "            resp = requests.post(_SERPER_SEARCH_URL, headers=headers, json=payload)\n",
    "            #print('Serper response: ', resp)\n",
    "            #print('Serper response code: ', resp.json())\n",
    "            \n",
    "            if resp.status_code != 200:\n",
    "                raise Exception(f\"Serper API Error: {resp.text}\")\n",
    "            results = resp.json()\n",
    "            #print('Serper results: ', results.type)\n",
    "\n",
    "            #return results\n",
    "            \n",
    "            documents = []\n",
    "            for i, item in enumerate(results.get(\"news\", []), 1):\n",
    "                title = item.get('title')\n",
    "                link = item.get('link')\n",
    "                snippet = item.get('snippet')\n",
    "                documents.append(Document(\n",
    "                    page_content=f\"{title}\\n{snippet}\",\n",
    "                    metadata={\"source\": link}\n",
    "                ))\n",
    "            \n",
    "            #if not documents:\n",
    "            #    empty_search = Exception(\"No result found\")\n",
    "            #    raise empty_search\n",
    "            \n",
    "            #print(f\"Retrieved {len(documents)} documents from Serper.\")\n",
    "            return documents\n",
    "        except Exception as e:\n",
    "            if e is empty_search:\n",
    "                print('serper main exception1')\n",
    "                raise empty_search\n",
    "            else:\n",
    "                print('serper main exception2')\n",
    "                raise e\n",
    "        \n",
    "def verify_news(user_claim, i_model_multi_query, i_model_summarizer, i_model_judge, input_lang = 'auto'):\n",
    "    \"\"\"\n",
    "       Description: This function is used to verify the claim provided by the user and output as REAL or FAKE or UNSURE based on the context with a short explanation\n",
    "       INPUT: user_claim --> The news user wish to verify\n",
    "       OUTPUT: FAKE/REAL/UNSURE with explanation\n",
    "    \"\"\"\n",
    "    try:\n",
    "       model_multi_query = i_model_multi_query\n",
    "       model_summarizer = i_model_summarizer\n",
    "       model_judge = i_model_judge\n",
    "\n",
    "       #print('here1: ', user_claim)\n",
    "       claim1 = user_claim.replace(\"'\",\"\")\n",
    "       claim1 = claim1.replace(\"\\n\",\" \")\n",
    "       #print('here2: ', claim1)\n",
    "        \n",
    "       serper_retriever = SerperRetrieverWrapper(api_key=serp_dev_api_key)\n",
    "       context_retriever = RunnableLambda(serper_retriever.get_relevant_documents)\n",
    "       \n",
    "       \"\"\"\n",
    "       Implemeting RAG framework with Multi Query Translation\n",
    "       Step 1 -- Take input from user for the news to verify\n",
    "       Step 2 -- Generate 3 variants of the news for better seach results\n",
    "       Step 3 -- Summarise the results from all the previous steps to be passed to main prompt\n",
    "       Step 4 -- Deliver the final verdict with a short explanation\n",
    "       \"\"\"\n",
    "       \n",
    "       #Multi Query Generation\n",
    "       \n",
    "       multi_query_template = \"\"\"\n",
    "            You are an AI language assistant.\n",
    "\n",
    "             Your task is to generate three alternative phrasings of the given user question to help retrieve relevant documents from a vector database. These alternatives should reflect different ways the original question might be asked, using varied vocabulary or structure, while preserving the original intent.             \n",
    "             This helps improve the chances of matching relevant content in a distance-based similarity search.\n",
    "             \n",
    "             Original question: {question}\n",
    "             \n",
    "             Output:\n",
    "             Provide exactly three reworded versions of the question, each on a new line.\n",
    "       \"\"\"\n",
    "       perspectives_prompt = ChatPromptTemplate.from_template(multi_query_template)\n",
    "       \n",
    "       llm_multi_query = ChatGroq(api_key = grok_api_key, model_name = model_multi_query)\n",
    "       \n",
    "       generate_queries = (\n",
    "           perspectives_prompt \n",
    "           | llm_multi_query\n",
    "           | StrOutputParser() \n",
    "           | (lambda x: x.split(\"\\n\"))\n",
    "       )\n",
    "       \n",
    "       \"\"\"\n",
    "       #Summarization using multi query\n",
    "       \n",
    "       summarizer_template = '''\n",
    "          You are an assistant summarizing factual evidence from multiple documents.\n",
    "       \n",
    "          Based on the following documents, extract the key facts relevant to the claim.\n",
    "          \n",
    "          Claim: {question}\n",
    "          \n",
    "          Documents:\n",
    "          {context}\n",
    "          \n",
    "          Return a short neutral summary of the key facts only.\n",
    "       '''\n",
    "       summarizer_prompt = PromptTemplate.from_template(summarizer_template)\n",
    "       \n",
    "       llm_summarizer = ChatGroq(api_key = grok_api_key, model_name = model_summarizer)\n",
    "       summarizer_chain = (\n",
    "           {\n",
    "               \"context\": context_retriever,\n",
    "               \"question\": generate_queries\n",
    "           }\n",
    "           | summarizer_prompt\n",
    "           | llm_summarizer\n",
    "           | StrOutputParser()\n",
    "       )\n",
    "       \"\"\"\n",
    "       \n",
    "       #Final Judgement \n",
    "       \n",
    "       fact_checker_template = '''\n",
    "          You are a fact-checking assistant.\n",
    "          \n",
    "          Claim: {question}\n",
    "          \n",
    "          Evidence:\n",
    "          {evidence}\n",
    "          \n",
    "          Instructions:\n",
    "          \n",
    "          If evidence is provided, use only that evidence to determine whether the claim is REAL, FAKE, or UNSURE.          \n",
    "          \n",
    "          If no sufficient or conclusive evidence is found from these sources, respond with UNSURE.          \n",
    "          Do not speculate or rely on untrusted sources.\n",
    "\n",
    "          Respond in this format:\n",
    "          \n",
    "          Classification: REAL / FAKE / UNSURE  \n",
    "          Explanation: <Your reasoning, clearly supported by the evidence or source content> \n",
    "       '''\n",
    "       \n",
    "       fact_checker_prompt = PromptTemplate.from_template(fact_checker_template)\n",
    "       \n",
    "       llm_fact_checker = ChatGroq(api_key = grok_api_key, model_name = model_judge)\n",
    "       fact_checker_chain = (\n",
    "           {\n",
    "               \"question\": RunnablePassthrough(),\n",
    "               \"evidence\": context_retriever \n",
    "           }\n",
    "           | fact_checker_prompt\n",
    "           | llm_fact_checker\n",
    "           | StrOutputParser()\n",
    "       )\n",
    "   \n",
    "       claim = claim1\n",
    "       \n",
    "       #Calling SARVAM API to translate Indic languages to English\n",
    "       client = SarvamAI(api_subscription_key = sarvam_api_key)\n",
    "       \n",
    "       try:\n",
    "           translation = client.text.translate(\n",
    "           input=claim,\n",
    "           source_language_code=\"auto\",\n",
    "           target_language_code=\"en-IN\"\n",
    "           )\n",
    "       except Exception as e:\n",
    "           print(f\"Error during translation: {e}\")\n",
    "           error_msg = 'It appears you have provided input in an alien language. Please try again with some other language'\n",
    "           return error_msg,error_msg,error_msg\n",
    "       \n",
    "       claim_final = translation.translated_text if translation else claim\n",
    "       claim_orig_lang = translation.source_language_code\n",
    "       #print(f\"Translated claim: {claim_final}\")\n",
    "       \n",
    "       verdict_orig = fact_checker_chain.invoke(claim_final)\n",
    "       verdict_class = verdict_orig.split('\\n')[0]\n",
    "       verdict_explan = verdict_orig.split('\\n')[-1]\n",
    "\n",
    "       # Strip out any <think> or <tool> or similar tags\n",
    "       cleaned_output = re.sub(r\"<[^>]+>\", \"\", verdict_orig).strip()\n",
    "       \n",
    "       verdict_class = re.search(r'Classification:\\s*(REAL|FAKE|UNSURE)', cleaned_output)\n",
    "       verdict_explan = re.search(r'Explanation:\\s*(.*)', cleaned_output, re.DOTALL)\n",
    "       \n",
    "       verdict_class = verdict_class.group(1) if verdict_class else \"UNSURE\"\n",
    "       verdict_explan = verdict_explan.group(1).strip() if verdict_explan else \"No clear explanation found.\"\n",
    "\n",
    "       #print('here1: ',verdict_class)\n",
    "       #print('here2: ',verdict_explan)\n",
    "       \n",
    "       if input_lang == 'auto':\n",
    "           trans_lang = claim_orig_lang\n",
    "       else:\n",
    "           trans_lang = input_lang\n",
    "   \n",
    "       if claim_orig_lang != 'en-IN':\n",
    "           try:\n",
    "               translation_class = client.text.translate(\n",
    "               input=verdict_class,\n",
    "               source_language_code='en-IN',\n",
    "               target_language_code=claim_orig_lang\n",
    "               )\n",
    "           except Exception as e:\n",
    "               print(f\"Error during verdict translation: {e}\")  \n",
    "               error_msg = 'Something went wrong while translating the verdict. Please try again'\n",
    "               return error_msg,error_msg,error_msg\n",
    "               \n",
    "           try:\n",
    "               translation_explan = client.text.translate(\n",
    "               input=verdict_explan,\n",
    "               source_language_code='en-IN',\n",
    "               target_language_code=claim_orig_lang\n",
    "               )\n",
    "           except Exception as e:\n",
    "               print(f\"Error during verdict translation: {e}\")  \n",
    "               error_msg = 'Something went wrong while translating the verdict. Please try again'\n",
    "               return error_msg,error_msg,error_msg\n",
    "           \n",
    "           verdict_trans_class = translation_class.translated_text\n",
    "           verdict_trans_explan = translation_explan.translated_text\n",
    "           verdict_trans = verdict_trans_class + '\\n\\n' + verdict_trans_explan\n",
    "           \n",
    "           verdict_orig = verdict_class + '\\n\\n' + verdict_explan\n",
    "       else:\n",
    "           verdict_orig = verdict_class + '\\n\\n' + verdict_explan\n",
    "           verdict_trans_class = verdict_class\n",
    "           verdict_trans_explan = verdict_explan\n",
    "           verdict_trans = verdict_trans_class + '\\n\\n' + verdict_trans_explan\n",
    "           #print('verdict_orig: ', verdict_orig) \n",
    "           \n",
    "           try:\n",
    "               match = re.search(r':(.*)', verdict_class)\n",
    "               if match:\n",
    "                    verdict1 = match.group(1).strip()\n",
    "                    #print(verdict1)\n",
    "           except Exception as e:\n",
    "               print('here3')\n",
    "               verdict1 = verdict_class\n",
    "       \n",
    "       #return(claim_final, verdict_orig, verdict_trans)\n",
    "       return(claim_final, verdict_class, verdict_orig)\n",
    "    except Exception as e:\n",
    "        if str(e) == 'No result found':\n",
    "            print('Error in main proc1. Error is ', e)\n",
    "            error_msg = 'The search for this claim came back empty. Please rephrase the claim or try with a new one'\n",
    "            return('UNSURE' ,error_msg,error_msg)\n",
    "        else:\n",
    "            print('Error in main proc2. Error is ', e)\n",
    "            error_msg = 'Something went wrong. Please try after some time'\n",
    "            return(error_msg,error_msg,error_msg)\n",
    "    \n",
    "def transcribe_audio(audio):\n",
    "    \"\"\"\n",
    "       Description: This function trascibes audio using SarvamAI STT model \n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = SarvamAI(api_subscription_key = sarvam_api_key)\n",
    "        mime_type, _ = mimetypes.guess_type(audio)\n",
    "        \n",
    "        with open(audio, \"rb\") as f:\n",
    "            response = client.speech_to_text.transcribe(\n",
    "                file=(\"audio.mp3\", f, mime_type or \"audio/mpeg\"),\n",
    "                model=\"saarika:v2.5\",\n",
    "                language_code=\"unknown\"\n",
    "            )\n",
    "        ret_var = response.transcript\n",
    "        ret_lang = response.language_code\n",
    "    except Exception as e:\n",
    "        print(f\"Error during translation: {e}\")\n",
    "        ret_var = ''\n",
    "\n",
    "    return ret_var, ret_lang\n",
    "    \n",
    "def verify_news_audio(audio):\n",
    "    \"\"\"\n",
    "       Description: This function verifies the news where input method is Audio\n",
    "    \"\"\"\n",
    "    \n",
    "    claim, orig_lang = transcribe_audio(audio)\n",
    "    if claim == '':\n",
    "        error_msg = 'I could not understand your message. Please try recording again'\n",
    "        return(error_msg,error_msg,error_msg)\n",
    "    \n",
    "    final_claim, verdict, verdict_trans = verify_news(claim, orig_lang)\n",
    "    return final_claim, verdict, verdict_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1479c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_regional = model_evaluate('fake_news_claims_factchecked_reginal.csv')\n",
    "df_test_regional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9c6cef",
   "metadata": {},
   "source": [
    "Evaluating performance with input as Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3045d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import mimetypes\n",
    "import os\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "from sarvamai import SarvamAI\n",
    "import re\n",
    "\n",
    "grok_api_key = os.getenv('GROK_API_KEY')\n",
    "serp_dev_api_key = os.getenv('SERP_DEV_API_KEY')\n",
    "sarvam_api_key = os.getenv('SARVAM_API_KEY')\n",
    "\n",
    "empty_search = None\n",
    "\n",
    "class SerperRetrieverWrapper:\n",
    "    #Class to use Serper as retriver agent for the RAG framework\n",
    "    def __init__(self, api_key: str, num_results: int = 15):\n",
    "        self.api_key = api_key\n",
    "        self.num_results = num_results\n",
    "    \n",
    "    def get_relevant_documents(self, query: str):\n",
    "        \"\"\"\n",
    "        Query Serper.dev and return up to `num_results` organic search hits.\n",
    "        Each hit is a dict: { \"title\": str, \"link\": str, \"snippet\": str }.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            _SERPER_SEARCH_URL = \"https://google.serper.dev/news\"\n",
    "            q1 = '(site:news18.com OR site:ptinews.com OR site:politifact.com) ' + query\n",
    "            #print('Serper query: ', q1)\n",
    "    \n",
    "            headers = {\n",
    "                \"X-API-KEY\": self.api_key,\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "            payload = {\n",
    "                \"q\": q1,\n",
    "                \"num\": self.num_results,\n",
    "            }\n",
    "            \n",
    "            resp = requests.post(_SERPER_SEARCH_URL, headers=headers, json=payload)\n",
    "            #print('Serper response: ', resp)\n",
    "            #print('Serper response code: ', resp.json())\n",
    "            \n",
    "            if resp.status_code != 200:\n",
    "                raise Exception(f\"Serper API Error: {resp.text}\")\n",
    "            results = resp.json()\n",
    "            #print('Serper results: ', results.type)\n",
    "\n",
    "            #return results\n",
    "            \n",
    "            documents = []\n",
    "            for i, item in enumerate(results.get(\"news\", []), 1):\n",
    "                title = item.get('title')\n",
    "                link = item.get('link')\n",
    "                snippet = item.get('snippet')\n",
    "                documents.append(Document(\n",
    "                    page_content=f\"{title}\\n{snippet}\",\n",
    "                    metadata={\"source\": link}\n",
    "                ))\n",
    "            \n",
    "            #if not documents:\n",
    "            #    empty_search = Exception(\"No result found\")\n",
    "            #    raise empty_search\n",
    "            \n",
    "            #print(f\"Retrieved {len(documents)} documents from Serper.\")\n",
    "            return documents\n",
    "        except Exception as e:\n",
    "            if e is empty_search:\n",
    "                print('serper main exception1')\n",
    "                raise empty_search\n",
    "            else:\n",
    "                print('serper main exception2')\n",
    "                raise e\n",
    "        \n",
    "def verify_news(user_claim, i_model_multi_query, i_model_summarizer, i_model_judge, input_lang = 'auto'):\n",
    "    \"\"\"\n",
    "       Description: This function is used to verify the claim provided by the user and output as REAL or FAKE or UNSURE based on the context with a short explanation\n",
    "       INPUT: user_claim --> The news user wish to verify\n",
    "       OUTPUT: FAKE/REAL/UNSURE with explanation\n",
    "    \"\"\"\n",
    "    try:\n",
    "       model_multi_query = i_model_multi_query\n",
    "       model_summarizer = i_model_summarizer\n",
    "       model_judge = i_model_judge\n",
    "\n",
    "       #print('here1: ', user_claim)\n",
    "       claim1 = user_claim.replace(\"'\",\"\")\n",
    "       claim1 = claim1.replace(\"\\n\",\" \")\n",
    "       #print('here2: ', claim1)\n",
    "        \n",
    "       serper_retriever = SerperRetrieverWrapper(api_key=serp_dev_api_key)\n",
    "       context_retriever = RunnableLambda(serper_retriever.get_relevant_documents)\n",
    "       \n",
    "       \"\"\"\n",
    "       Implemeting RAG framework with Multi Query Translation\n",
    "       Step 1 -- Take input from user for the news to verify\n",
    "       Step 2 -- Generate 3 variants of the news for better seach results\n",
    "       Step 3 -- Summarise the results from all the previous steps to be passed to main prompt\n",
    "       Step 4 -- Deliver the final verdict with a short explanation\n",
    "       \"\"\"\n",
    "       \n",
    "       #Multi Query Generation\n",
    "       \n",
    "       multi_query_template = \"\"\"\n",
    "            You are an AI language assistant.\n",
    "\n",
    "             Your task is to generate three alternative phrasings of the given user question to help retrieve relevant documents from a vector database. These alternatives should reflect different ways the original question might be asked, using varied vocabulary or structure, while preserving the original intent.             \n",
    "             This helps improve the chances of matching relevant content in a distance-based similarity search.\n",
    "             \n",
    "             Original question: {question}\n",
    "             \n",
    "             Output:\n",
    "             Provide exactly three reworded versions of the question, each on a new line.\n",
    "       \"\"\"\n",
    "       perspectives_prompt = ChatPromptTemplate.from_template(multi_query_template)\n",
    "       \n",
    "       llm_multi_query = ChatGroq(api_key = grok_api_key, model_name = model_multi_query)\n",
    "       \n",
    "       generate_queries = (\n",
    "           perspectives_prompt \n",
    "           | llm_multi_query\n",
    "           | StrOutputParser() \n",
    "           | (lambda x: x.split(\"\\n\"))\n",
    "       )\n",
    "       \n",
    "       \"\"\"\n",
    "       #Summarization using multi query\n",
    "       \n",
    "       summarizer_template = '''\n",
    "          You are an assistant summarizing factual evidence from multiple documents.\n",
    "       \n",
    "          Based on the following documents, extract the key facts relevant to the claim.\n",
    "          \n",
    "          Claim: {question}\n",
    "          \n",
    "          Documents:\n",
    "          {context}\n",
    "          \n",
    "          Return a short neutral summary of the key facts only.\n",
    "       '''\n",
    "       summarizer_prompt = PromptTemplate.from_template(summarizer_template)\n",
    "       \n",
    "       llm_summarizer = ChatGroq(api_key = grok_api_key, model_name = model_summarizer)\n",
    "       summarizer_chain = (\n",
    "           {\n",
    "               \"context\": context_retriever,\n",
    "               \"question\": generate_queries\n",
    "           }\n",
    "           | summarizer_prompt\n",
    "           | llm_summarizer\n",
    "           | StrOutputParser()\n",
    "       )\n",
    "       \"\"\"\n",
    "       \n",
    "       #Final Judgement \n",
    "       \n",
    "       fact_checker_template = '''\n",
    "          You are a fact-checking assistant.\n",
    "          \n",
    "          Claim: {question}\n",
    "          \n",
    "          Evidence:\n",
    "          {evidence}\n",
    "          \n",
    "          Instructions:\n",
    "          \n",
    "          If evidence is provided, use only that evidence to determine whether the claim is REAL, FAKE, or UNSURE.          \n",
    "          \n",
    "          If no sufficient or conclusive evidence is found from these sources, respond with UNSURE.          \n",
    "          Do not speculate or rely on untrusted sources.\n",
    "\n",
    "          Respond in this format:\n",
    "          \n",
    "          Classification: REAL / FAKE / UNSURE  \n",
    "          Explanation: <Your reasoning, clearly supported by the evidence or source content> \n",
    "       '''\n",
    "       \n",
    "       fact_checker_prompt = PromptTemplate.from_template(fact_checker_template)\n",
    "       \n",
    "       llm_fact_checker = ChatGroq(api_key = grok_api_key, model_name = model_judge)\n",
    "       fact_checker_chain = (\n",
    "           {\n",
    "               \"question\": RunnablePassthrough(),\n",
    "               \"evidence\": context_retriever \n",
    "           }\n",
    "           | fact_checker_prompt\n",
    "           | llm_fact_checker\n",
    "           | StrOutputParser()\n",
    "       )\n",
    "   \n",
    "       claim = claim1\n",
    "       \n",
    "       #Calling SARVAM API to translate Indic languages to English\n",
    "       client = SarvamAI(api_subscription_key = sarvam_api_key)\n",
    "       \n",
    "       try:\n",
    "           translation = client.text.translate(\n",
    "           input=claim,\n",
    "           source_language_code=\"auto\",\n",
    "           target_language_code=\"en-IN\"\n",
    "           )\n",
    "       except Exception as e:\n",
    "           print(f\"Error during translation: {e}\")\n",
    "           error_msg = 'It appears you have provided input in an alien language. Please try again with some other language'\n",
    "           return error_msg,error_msg,error_msg\n",
    "       \n",
    "       claim_final = translation.translated_text if translation else claim\n",
    "       claim_orig_lang = translation.source_language_code\n",
    "       #print(f\"Translated claim: {claim_final}\")\n",
    "       \n",
    "       verdict_orig = fact_checker_chain.invoke(claim_final)\n",
    "       verdict_class = verdict_orig.split('\\n')[0]\n",
    "       verdict_explan = verdict_orig.split('\\n')[-1]\n",
    "\n",
    "       # Strip out any <think> or <tool> or similar tags\n",
    "       cleaned_output = re.sub(r\"<[^>]+>\", \"\", verdict_orig).strip()\n",
    "       \n",
    "       verdict_class = re.search(r'Classification:\\s*(REAL|FAKE|UNSURE)', cleaned_output)\n",
    "       verdict_explan = re.search(r'Explanation:\\s*(.*)', cleaned_output, re.DOTALL)\n",
    "       \n",
    "       verdict_class = verdict_class.group(1) if verdict_class else \"UNSURE\"\n",
    "       verdict_explan = verdict_explan.group(1).strip() if verdict_explan else \"No clear explanation found.\"\n",
    "\n",
    "       #print('here1: ',verdict_class)\n",
    "       #print('here2: ',verdict_explan)\n",
    "       \n",
    "       if input_lang == 'auto':\n",
    "           trans_lang = claim_orig_lang\n",
    "       else:\n",
    "           trans_lang = input_lang\n",
    "   \n",
    "       if claim_orig_lang != 'en-IN':\n",
    "           try:\n",
    "               translation_class = client.text.translate(\n",
    "               input=verdict_class,\n",
    "               source_language_code='en-IN',\n",
    "               target_language_code=claim_orig_lang\n",
    "               )\n",
    "           except Exception as e:\n",
    "               print(f\"Error during verdict translation: {e}\")  \n",
    "               error_msg = 'Something went wrong while translating the verdict. Please try again'\n",
    "               return error_msg,error_msg,error_msg\n",
    "               \n",
    "           try:\n",
    "               translation_explan = client.text.translate(\n",
    "               input=verdict_explan,\n",
    "               source_language_code='en-IN',\n",
    "               target_language_code=claim_orig_lang\n",
    "               )\n",
    "           except Exception as e:\n",
    "               print(f\"Error during verdict translation: {e}\")  \n",
    "               error_msg = 'Something went wrong while translating the verdict. Please try again'\n",
    "               return error_msg,error_msg,error_msg\n",
    "           \n",
    "           verdict_trans_class = translation_class.translated_text\n",
    "           verdict_trans_explan = translation_explan.translated_text\n",
    "           verdict_trans = verdict_trans_class + '\\n\\n' + verdict_trans_explan\n",
    "           \n",
    "           verdict_orig = verdict_class + '\\n\\n' + verdict_explan\n",
    "       else:\n",
    "           verdict_orig = verdict_class + '\\n\\n' + verdict_explan\n",
    "           verdict_trans_class = verdict_class\n",
    "           verdict_trans_explan = verdict_explan\n",
    "           verdict_trans = verdict_trans_class + '\\n\\n' + verdict_trans_explan\n",
    "           #print('verdict_orig: ', verdict_orig) \n",
    "           \n",
    "           try:\n",
    "               match = re.search(r':(.*)', verdict_class)\n",
    "               if match:\n",
    "                    verdict1 = match.group(1).strip()\n",
    "                    #print(verdict1)\n",
    "           except Exception as e:\n",
    "               print('here3')\n",
    "               verdict1 = verdict_class\n",
    "       \n",
    "       #return(claim_final, verdict_orig, verdict_trans)\n",
    "       return(claim_final, verdict_class, verdict_orig)\n",
    "    except Exception as e:\n",
    "        if str(e) == 'No result found':\n",
    "            print('Error in main proc1. Error is ', e)\n",
    "            error_msg = 'The search for this claim came back empty. Please rephrase the claim or try with a new one'\n",
    "            return('UNSURE' ,error_msg,error_msg)\n",
    "        else:\n",
    "            print('Error in main proc2. Error is ', e)\n",
    "            error_msg = 'Something went wrong. Please try after some time'\n",
    "            return(error_msg,error_msg,error_msg)\n",
    "    \n",
    "def transcribe_audio(audio):\n",
    "    \"\"\"\n",
    "       Description: This function trascibes audio using SarvamAI STT model \n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = SarvamAI(api_subscription_key = sarvam_api_key)\n",
    "        mime_type, _ = mimetypes.guess_type(audio)\n",
    "        \n",
    "        with open(audio, \"rb\") as f:\n",
    "            response = client.speech_to_text.transcribe(\n",
    "                file=(\"audio.mp3\", f, mime_type or \"audio/mpeg\"),\n",
    "                model=\"saarika:v2.5\",\n",
    "                language_code=\"unknown\"\n",
    "            )\n",
    "        ret_var = response.transcript\n",
    "        ret_lang = response.language_code\n",
    "    except Exception as e:\n",
    "        print(f\"Error during translation: {e}\")\n",
    "        ret_var = ''\n",
    "\n",
    "    return ret_var, ret_lang\n",
    "    \n",
    "def verify_news_audio(audio,i_model_multi_query, i_model_summarizer, i_model_judge):\n",
    "    \"\"\"\n",
    "       Description: This function verifies the news where input method is Audio\n",
    "    \"\"\"\n",
    "    \n",
    "    claim, orig_lang = transcribe_audio(audio)\n",
    "    if claim == '':\n",
    "        error_msg = 'I could not understand your message. Please try recording again'\n",
    "        return(error_msg,error_msg,error_msg)\n",
    "    \n",
    "    final_claim, verdict, verdict_trans = verify_news(claim, i_model_multi_query, i_model_summarizer, i_model_judge,orig_lang)\n",
    "    return final_claim, verdict, verdict_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(columns=['model_judge','claim_trans','veridict_class','veridict_full','file_name'])\n",
    "for i in os.listdir('C:\\\\Users\\\\rahul\\\\OneDrive\\\\7_Learning\\\\IISC\\\\Courses\\\\3.1_Deep_Learning\\\\Course Material\\\\Project\\\\wip\\\\audio\\\\'):\n",
    "    if i.endswith('.mp3'):\n",
    "        print('Processing file: ', i)\n",
    "        audio_path = os.path.join('C:\\\\Users\\\\rahul\\\\OneDrive\\\\7_Learning\\\\IISC\\\\Courses\\\\3.1_Deep_Learning\\\\Course Material\\\\Project\\\\wip\\\\audio', i)\n",
    "        #models = ['qwen-qwq-32b','llama3-8b-8192','qwen/qwen3-32b','mistral-saba-24b','deepseek-r1-distill-llama-70b',\n",
    "        #  'meta-llama/llama-4-scout-17b-16e-instruct',  'meta-llama/llama-4-maverick-17b-128e-instruct']\n",
    "\n",
    "        models = ['qwen-qwq-32b','llama3-8b-8192','mistral-saba-24b']\n",
    "        #  'meta-llama/llama-4-scout-17b-16e-instruct',  'meta-llama/llama-4-maverick-17b-128e-instruct']\n",
    "\n",
    "        df_model_res =pd.DataFrame(columns=['model_multi_query', 'model_summarizer', 'model_judge', 'abstention_rate', 'accuracy', 'overall_accuracy', 'coverage', 'abstention_rate', 'f1_real', 'f1_fake'])    \n",
    "        \n",
    "        \n",
    "        for judge_model in models:\n",
    "             model_multi_query = models[0]  # Keep constant\n",
    "             model_summarizer = models[1]   # Keep constant  \n",
    "             model_judge = judge_model      # Test each one\n",
    "             print(f\"Testing with judge: {judge_model}\")\n",
    "            \n",
    "             claim_trans, veridict_class, verdict_full = verify_news_audio(audio_path, model_multi_query, model_summarizer, model_judge)\n",
    "\n",
    "             lis1 = [model_judge , claim_trans, veridict_class, verdict_full, i]\n",
    "             df_res.loc[len(df_res)] = lis1\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02205ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_judge</th>\n",
       "      <th>claim_trans</th>\n",
       "      <th>veridict_class</th>\n",
       "      <th>veridict_full</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qwen-qwq-32b</td>\n",
       "      <td>The 2000 rupee note has a GPS tracker.</td>\n",
       "      <td>UNSURE</td>\n",
       "      <td>UNSURE\\n\\nThe provided evidence consists of Politifact fact-checks focused on U.S. political topics such as immigration, voter fraud, job creation, and policy history. None of the documents mention India's 2000 rupee note or GPS trackers in currency. Since the evidence does not address the claim, there is no basis to confirm or refute it using the given sources.</td>\n",
       "      <td>2000.mp3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_judge                             claim_trans veridict_class  \\\n",
       "0  qwen-qwq-32b  The 2000 rupee note has a GPS tracker.         UNSURE   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                  veridict_full  \\\n",
       "0  UNSURE\\n\\nThe provided evidence consists of Politifact fact-checks focused on U.S. political topics such as immigration, voter fraud, job creation, and policy history. None of the documents mention India's 2000 rupee note or GPS trackers in currency. Since the evidence does not address the claim, there is no basis to confirm or refute it using the given sources.   \n",
       "\n",
       "  file_name  \n",
       "0  2000.mp3  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b71e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##For all distnct model judge run below codes manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e0cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aacd19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143fc840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045f4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33073b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa4407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7942883e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a6863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf4c9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75430ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d584480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dfead6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2a6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26dad3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312a6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838be215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
